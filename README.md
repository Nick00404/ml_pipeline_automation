# ML Pipeline Automation Project

This project is a comprehensive, **production-ready machine learning pipeline** designed for flexibility and scalability across many industries. It integrates **state-of-the-art MLOps tools** and provides a modular, configurable structure for data ingestion, preprocessing, training, deployment, monitoring, and auto-retraining.


## ğŸš€ What You'll Get

âœ… How to structure a real-world ML pipeline  
âœ… How to modularize and reuse your code  
âœ… How to automate training workflows  
âœ… How to deploy models using FastAPI and Docker  
âœ… How to monitor production ML systems  
âœ… How to configure pipelines without changing code  

## Project Structure

```
ml_pipeline_automation/
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .env
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ Makefile
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .dockerignore
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ deploy.yml
â”œâ”€â”€ autoretrain/
â”‚   â”œâ”€â”€ auto_retrain.py
â”‚   â””â”€â”€ schedule.sh
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ model_config.yaml
â”‚   â””â”€â”€ training_config.yaml
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/ (.gitkeep)
â”‚   â””â”€â”€ processed/ (.gitkeep)
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ App.js
â”‚       â”œâ”€â”€ index.html
â”‚       â””â”€â”€ index.js
â”œâ”€â”€ logs/ (.gitkeep)
â”œâ”€â”€ models/ (.gitkeep)
â”œâ”€â”€ monitoring/
â”‚   â”œâ”€â”€ prometheus.yml
â”‚   â””â”€â”€ dashboards/
â”‚       â””â”€â”€ fastapi_dashboard.json
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ sample_notebook.ipynb
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ deploy_aws.sh
â”‚   â”œâ”€â”€ run_training.sh
â”‚   â””â”€â”€ start_server.sh
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data.py
â”‚   â”œâ”€â”€ data_cleaning.py
â”‚   â”œâ”€â”€ data_ingestion.py
â”‚   â”œâ”€â”€ feature_engineering.py
â”‚   â”œâ”€â”€ model.py
â”‚   â”œâ”€â”€ model_evaluation.py
â”‚   â”œâ”€â”€ model_server.py
â”‚   â”œâ”€â”€ model_training.py
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ utils.py
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ terraform/
â”‚   â”œâ”€â”€ main.tf
â”‚   â””â”€â”€ variables.tf
â””â”€â”€ tests/
    â”œâ”€â”€ test_api.py
    â””â”€â”€ test_model.py
```


## ğŸ§° Tech Stack

- **Python 3.10**  
- **FastAPI** for serving ML models  
- **scikit-learn** for model training  
- **Docker** for containerization  
- **GitHub Actions** for CI/CD  
- **Prometheus & Grafana** for monitoring  
- **Terraform** for cloud infrastructure  
- **YAML** for configuration  
- **React** for minimal dashboard  

---

## ğŸ”§ How It Works (Step-by-Step)

### 1. Add Your Dataset

Place your `.csv` file inside:

```
data/raw/
```

Make sure your dataset includes a `target` column. If not, update `train.py` and `configs/training_config.yaml` accordingly.

---

### 2. Install Dependencies

- Update `.env` File with your configuration.

```bash
pip install -r requirements.txt
```

---

### 3. Configure the Pipeline

Edit `configs/training_config.yaml` and `configs/model_config.yaml` to customize model type, parameters, train-test split, etc.

```yaml
model:
  type: "RandomForest"
  params:
    n_estimators: 100
    max_depth: 5

train_test_split:
  test_size: 0.2
  random_state: 42
```

---

### 4. Run the Pipeline

Run all steps â€” ingestion, preprocessing, training, evaluation â€” using:

```bash
python train.py
```

âœ”ï¸ The trained model will be saved in `models/`  
âœ”ï¸ Metrics and reports will be printed to the terminal  

---

## ğŸ“‚ Key Modules in `src/`

| File | Purpose |
|------|---------|
| `data_ingestion.py` | Load raw data |
| `data_cleaning.py` | Handle nulls, fix types |
| `feature_engineering.py` | Scale and encode features |
| `model_training.py` | Train model using YAML config |
| `model_evaluation.py` | Print accuracy, classification report |
| `utils.py` | Helper functions (e.g., load YAML) |
| `api/` | FastAPI server for inference |

---

## ğŸ–¥ï¸ Serving the Model (API)

Once a model is trained, start the API server:

```bash
bash scripts/start_server.sh
```

Access it via:  
`http://localhost:8000/docs`  
Youâ€™ll see an interactive Swagger UI to test your ML model.

---

## â˜ï¸ Deploy to Cloud

Using **Terraform**, you can deploy the whole stack (Docker, FastAPI, Prometheus, Grafana) on an AWS EC2 instance.

```bash
cd terraform/
terraform init
terraform apply
```

Make sure your AWS credentials are set.

---

## ğŸ“Š Monitoring

- **Prometheus** scrapes metrics from your API.
- **Grafana** provides real-time dashboards.

Access Grafana via the browser (default port 3000). Dashboards are located in:

```
monitoring/dashboards/
```

---

## ğŸ”„ Auto-Retraining

Automatically retrain models on a schedule (e.g., every week):

- Edit `autoretrain/schedule.sh` and configure a cron job.
- The script will re-run `train.py` and log results.

---

## ğŸ§ª Testing

Unit tests are located in `tests/`. Run them using:

```bash
pytest tests/
```

---

## ğŸ’¡ Advanced Extensions (Ideas)

- Add MLflow for experiment tracking  
- Integrate Optuna for hyperparameter tuning  
- Add XGBoost or LightGBM as options in the config  
- Deploy the API with Kubernetes  
- Extend pipeline to handle regression problems  

---

## ğŸ™Œ Contribution

Found a bug? Have a feature idea? Want to improve docs?

Feel free to fork this repo, submit a pull request, or open an issue.  
This project is made to grow with your learning ğŸ“ˆ

---

## ğŸ“œ License

MIT License Â© 2025


